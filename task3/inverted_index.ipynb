{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b352eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a11febba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод для чтения лемм из файла в словарь\n",
    "def read_lemmas(lemmas_file_path):\n",
    "    lemmas_dict = {}\n",
    "    with open(lemmas_file_path, 'r') as lemmas_file:\n",
    "        for lemma_line in lemmas_file:\n",
    "            lemma_with_tokens = lemma_line.split(':')\n",
    "            lemma = lemma_with_tokens[0].strip()\n",
    "            tokens = [token.strip() for token in lemma_with_tokens[1].split(' ') if token.strip() != '']\n",
    "            lemmas_dict[lemma] = tokens\n",
    "    return lemmas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43e21822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir_path = '../Выкачка/'\n",
    "data_file_pattern = 'выкачка_'\n",
    "\n",
    "# Метод получения индекса файла из названия формата 'file_pattern_{index}.txt'\n",
    "def get_file_index(filename):\n",
    "    return int(filename[len(data_file_pattern):].replace('.txt', ''))\n",
    "\n",
    "# Метод создания инвертированного индекса на основе пары лемма - токены\n",
    "def count_inverted_index(lemma, words):\n",
    "    # Индексы файлов, которые связаны с переданной леммой\n",
    "    files_indices = []\n",
    "    # Проходим по всем файлам выкачек\n",
    "    for filename in os.listdir(data_dir_path):\n",
    "        if data_file_pattern not in filename:\n",
    "            continue\n",
    "        file_path = data_dir_path + filename\n",
    "        file_index = get_file_index(filename)\n",
    "        with open(file_path, 'r') as text_file:\n",
    "            # Ищем, есть ли в файле есть слово, связанное с леммой\n",
    "            file_data = text_file.read().lower()\n",
    "            if any(word in file_data for word in words):\n",
    "                file_index = get_file_index(filename)\n",
    "                files_indices.append(file_index)\n",
    "    # Сортируем полученные индексы файлов и отдаем в виде словаря лемма - индексы файлов\n",
    "    files_indices.sort()\n",
    "    return {lemma : files_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9af81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод для склеивания двух словарей\n",
    "def merge_dicts(dict1, dict2):\n",
    "    for key in dict2:\n",
    "        if key in dict1:\n",
    "            dict1[key] = dict1[key] + dict2[key]\n",
    "        else:\n",
    "            dict1[key] = dict2[key]\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7984212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод записи инвертированного индекса в файл в json формате\n",
    "def write_json_indices(file_path, indices):\n",
    "    sorted_indices_keys = sorted(indices.keys())\n",
    "    with open(file_path, 'w') as indices_file:\n",
    "        for index_key in sorted_indices_keys:\n",
    "            index_documents = indices[index_key]\n",
    "            index_line = {\"count\": len(index_documents), \"inverted_array\": index_documents, \"word\": index_key}\n",
    "            index_line_json = json.dumps(index_line)\n",
    "            indices_file.write(index_line_json + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "533ccef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод построения полного инвертированного индекса:\n",
    "# cтроим индекс для каждой леммы и затем склеиваем полученные словари\n",
    "# результат записывается в файл inverted_index.txt\n",
    "lemmas = read_lemmas('../lemmas.txt')\n",
    "inverted_indices = {}\n",
    "for lemma in lemmas:\n",
    "    lemma_inverted_index = count_inverted_index(lemma, lemmas[lemma])\n",
    "    inverted_indices = merge_dicts(inverted_indices, lemma_inverted_index)\n",
    "write_json_indices('../inverted_index.txt', inverted_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed07e9",
   "metadata": {},
   "source": [
    "# Булев поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59e42aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод получения инвертированного списка индексов из файла в формат словаря\n",
    "def get_inverted_index_dict():\n",
    "    inverted_index_dict = {}\n",
    "    with open('../inverted_index.txt', 'r') as index_file:\n",
    "        for line in index_file:\n",
    "            data = json.loads(line)\n",
    "            inverted_index_dict[data['word']] = data['inverted_array']\n",
    "    return inverted_index_dict\n",
    "\n",
    "# Метод получения ссылок на статьи на основе ее индекса\n",
    "def get_page_links_by_indices(index_list):\n",
    "    pages = []\n",
    "    with open('../index.txt', 'r') as pages_file:\n",
    "        for line in pages_file:\n",
    "            page_index_with_link = line.split(' ')\n",
    "            index = int(page_index_with_link[0])\n",
    "            if index in index_list:\n",
    "                pages.append(page_index_with_link[1].replace('\\n', ''))\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e5075e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод поиска, на вход подается строка в формате (слово (&/| слово){1-...})\n",
    "def search(text):\n",
    "    search_params = text.strip().split(' ')\n",
    "    # Если в поиске нет слов, то получаем пустой список статей\n",
    "    if len(search_params) < 1:\n",
    "        return []\n",
    "    inverted_indices = get_inverted_index_dict()\n",
    "    page_indices = []\n",
    "    if search_params[0] in inverted_indices:\n",
    "        page_indices = inverted_indices[search_params[0]]\n",
    "    # Для каждой пары оператор - слово находим на основе инвертированного списка индексов нужные индексы статей и используем пересечение/объединение\n",
    "    for i in range(1, len(search_params), 2):\n",
    "        operator = search_params[i]\n",
    "        search_word = search_params[i + 1]\n",
    "        search_word_page_indices = []\n",
    "        if search_word in inverted_indices:\n",
    "            search_word_page_indices = inverted_indices[search_word]\n",
    "        if operator == '&':\n",
    "            page_indices = list(set(page_indices) & set(search_word_page_indices))\n",
    "        elif operator == '|':\n",
    "            page_indices = list(set(page_indices) | set(search_word_page_indices))\n",
    "    return get_page_links_by_indices(set(page_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a5fce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/title/tt11934846/',\n",
       " 'https://www.imdb.com/title/tt9389998/',\n",
       " 'https://www.imdb.com/title/tt15097216/',\n",
       " 'https://www.imdb.com/title/tt9766332/',\n",
       " 'https://www.imdb.com/title/tt0986264/',\n",
       " 'https://www.imdb.com/title/tt8772296/',\n",
       " 'https://www.imdb.com/title/tt1464335/',\n",
       " 'https://www.imdb.com/title/tt9288030/',\n",
       " 'https://www.imdb.com/title/tt1520211/',\n",
       " 'https://www.imdb.com/title/tt5788792/',\n",
       " 'https://www.imdb.com/title/tt11252248/',\n",
       " 'https://www.imdb.com/title/tt0903747/',\n",
       " 'https://www.imdb.com/title/tt10944760/',\n",
       " 'https://www.imdb.com/title/tt0119558/',\n",
       " 'https://www.imdb.com/title/tt2278871/',\n",
       " 'https://www.imdb.com/title/tt12404772/',\n",
       " 'https://www.imdb.com/title/tt11686490/',\n",
       " 'https://www.imdb.com/title/tt0211915/',\n",
       " 'https://www.imdb.com/title/tt1879030/',\n",
       " 'https://www.imdb.com/title/tt0107977/',\n",
       " 'https://www.imdb.com/title/tt2872732/',\n",
       " 'https://www.imdb.com/title/tt2333784/',\n",
       " 'https://www.imdb.com/title/tt9738784/',\n",
       " 'https://www.imdb.com/title/tt9151230/',\n",
       " 'https://www.imdb.com/title/tt8664988/',\n",
       " 'https://www.imdb.com/title/tt6087226/',\n",
       " 'https://www.imdb.com/title/tt10525672/',\n",
       " 'https://www.imdb.com/title/tt11547520/',\n",
       " 'https://www.imdb.com/title/tt11815960/',\n",
       " 'https://www.imdb.com/title/tt11455654/',\n",
       " 'https://www.imdb.com/title/tt6304162/',\n",
       " 'https://www.imdb.com/title/tt1224378/',\n",
       " 'https://www.imdb.com/title/tt7176054/',\n",
       " 'https://www.imdb.com/title/tt7025388/',\n",
       " 'https://www.imdb.com/title/tt1234435/',\n",
       " 'https://www.imdb.com/title/tt12908084/']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('work & teacher | find | treasure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "67ab834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/title/tt11934846/',\n",
       " 'https://www.imdb.com/title/tt9389998/',\n",
       " 'https://www.imdb.com/title/tt15097216/',\n",
       " 'https://www.imdb.com/title/tt0986264/',\n",
       " 'https://www.imdb.com/title/tt1464335/',\n",
       " 'https://www.imdb.com/title/tt0211915/',\n",
       " 'https://www.imdb.com/title/tt10525672/']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('work | teacher & find | treasure')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
